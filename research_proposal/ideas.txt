Have a Gaussian Process representation for the utility function

within UCT algo -> continuous actions



Keep subtree of UCT; reset the visit count; reset the values;

reset both or keep a fraction of each

Include Value function Learning within UCT

	- Dyna2 (Transcient-Permanent memory)

Learning patterns

Drive exploration wrt progress
	- Lopes12

Actor critic + MCTS
	- Apply LSTDQ on trajectory + simulated data
	- Low pass filter/history to discard data through time
	- MCTS = transient data; traj = permanent data
	- Simulated data are different than data generated
	  with the target policy: good for actor-critic
	- No learning rate
	- if KLSTDQ -> no features selection
